{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 - Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f2a4dff5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, glob, re, warnings, time\n",
        "from functools import reduce\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ===== HDBSCAN (required for the HDBSCAN path) =====\n",
        "try:\n",
        "    import hdbscan\n",
        "    HAS_HDBSCAN = True\n",
        "except Exception:\n",
        "    HAS_HDBSCAN = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "50ad1d78",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# SPEED / QUALITY TOGGLES\n",
        "# =========================\n",
        "DATA_DIR = r\"D:/HealthAI Project/data\"   # folder that already contains CSVs (already extracted)\n",
        "\n",
        "DO_PCA = True\n",
        "PCA_COMPONENTS_MAX = 10\n",
        "TFIDF_MAX_FEATURES = 50\n",
        "\n",
        "# Hyperparameter sweep runs on a subset only:\n",
        "SEARCH_SUBSAMPLE_MAX_N = 15000\n",
        "SEARCH_GRID = [\n",
        "    {\"min_cluster_size\": 40,  \"min_samples\": None, \"metric\": \"euclidean\", \"cluster_selection_epsilon\": 0.0},\n",
        "    {\"min_cluster_size\": 50,  \"min_samples\": None, \"metric\": \"euclidean\", \"cluster_selection_epsilon\": 0.0},\n",
        "    {\"min_cluster_size\": 50,  \"min_samples\": 5,    \"metric\": \"euclidean\", \"cluster_selection_epsilon\": 0.0},\n",
        "    {\"min_cluster_size\": 50,  \"min_samples\": None, \"metric\": \"euclidean\",    \"cluster_selection_epsilon\": 0.0},\n",
        "    {\"min_cluster_size\": 40,  \"min_samples\": 20,   \"metric\": \"euclidean\", \"cluster_selection_epsilon\": 0.1, \"cluster_selection_method\": \"leaf\"},\n",
        "    {\"min_cluster_size\": 60,  \"min_samples\": 30,   \"metric\": \"euclidean\", \"cluster_selection_epsilon\": 0.1, \"cluster_selection_method\": \"leaf\"},\n",
        "    {\"min_cluster_size\": 100, \"min_samples\": None, \"metric\": \"euclidean\", \"cluster_selection_epsilon\": 0.0},\n",
        "    {\"min_cluster_size\": 100, \"min_samples\": 10,   \"metric\": \"euclidean\", \"cluster_selection_epsilon\": 0.0},\n",
        "    {\"min_cluster_size\": 50,  \"min_samples\": 5,    \"metric\": \"euclidean\", \"cluster_selection_epsilon\": 0.5},\n",
        "    {\"min_cluster_size\": 100, \"min_samples\": 10,   \"metric\": \"euclidean\", \"cluster_selection_epsilon\": 0.5},\n",
        "]\n",
        "\n",
        "# Final HDBSCAN fit: fit on subset, then label *all* points via approximate_predict\n",
        "FINAL_SUBSAMPLE_MAX_N = 20000\n",
        "HDBSCAN_KW = dict(\n",
        "    cluster_selection_method=\"eom\",  # may be overridden per-cfg\n",
        "    prediction_data=True,\n",
        "    approx_min_span_tree=True,\n",
        "    gen_min_span_tree=False,\n",
        "    core_dist_n_jobs=-1\n",
        ")\n",
        "\n",
        "# Flag \"borderline\" core points by membership strength\n",
        "BORDERLINE_THRESH = 0.20\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "pd.set_option(\"display.max_columns\", 120)\n",
        "\n",
        "# =========================\n",
        "# File helpers\n",
        "# =========================\n",
        "def find_one_any(base_dir, rel_candidates, must=False, friendly=\"\"):\n",
        "    rel_candidates = [c.replace(\"\\\\\", \"/\") for c in rel_candidates]\n",
        "    want = {os.path.basename(c).lower() for c in rel_candidates}\n",
        "    for root, _, files in os.walk(base_dir):\n",
        "        for f in files:\n",
        "            if f.lower() in want:\n",
        "                path = os.path.join(root, f)\n",
        "                print(f\"[found] {friendly or 'file'} -> {path}\")\n",
        "                return path\n",
        "    if must:\n",
        "        raise FileNotFoundError(f\"Could not find one of {rel_candidates} under {base_dir}\")\n",
        "    return None\n",
        "\n",
        "def read_csv_auto(path):\n",
        "    if path is None: return None\n",
        "    comp = \"gzip\" if str(path).lower().endswith(\".gz\") else None\n",
        "    return pd.read_csv(path, compression=comp, low_memory=False)\n",
        "\n",
        "def print_header(title):\n",
        "    print(\"\\n\" + \"=\"*len(title))\n",
        "    print(title)\n",
        "    print(\"=\"*len(title))\n",
        "\n",
        "def coalesce_subject_id(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Ensure a single 'subject_id' column exists, combining _x/_y if present.\"\"\"\n",
        "    if \"subject_id\" in df.columns:\n",
        "        return df\n",
        "    s1 = df[\"subject_id_x\"] if \"subject_id_x\" in df.columns else pd.Series(index=df.index, dtype=\"float\")\n",
        "    s2 = df[\"subject_id_y\"] if \"subject_id_y\" in df.columns else pd.Series(index=df.index, dtype=\"float\")\n",
        "    if (\"subject_id_x\" in df.columns) or (\"subject_id_y\" in df.columns):\n",
        "        df[\"subject_id\"] = s1.combine_first(s2)\n",
        "        drop_cols = [c for c in [\"subject_id_x\",\"subject_id_y\"] if c in df.columns]\n",
        "        df = df.drop(columns=drop_cols)\n",
        "    return df\n",
        "\n",
        "def _metric_supported(metric: str) -> bool:\n",
        "    return metric in {\"euclidean\", \"l1\", \"l2\", \"manhattan\", \"cityblock\", \"cosine\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "76484c72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[found] file -> D:/HealthAI Project/data\\MIMIC IV\\patients.csv\n",
            "[found] file -> D:/HealthAI Project/data\\MIMIC IV\\admissions.csv\n",
            "[found] file -> D:/HealthAI Project/data\\MIMIC IV\\vitalsign.csv\n",
            "[found] file -> D:/HealthAI Project/data\\MIMIC IV\\labevents.csv\n",
            "[found] file -> D:/HealthAI Project/data\\MIMIC IV\\d_labitems.csv\n",
            "[found] file -> D:/HealthAI Project/data\\MIMIC IV\\prescriptions.csv\n",
            "[found] file -> D:/HealthAI Project/data\\MIMIC IV\\pharmacy.csv\n",
            "\n",
            "=============\n",
            "Files present\n",
            "=============\n",
            "{'patients': True, 'admissions': True, 'vitals': True, 'labevents': True, 'd_labitems': True, 'prescriptions': True, 'pharmacy': True}\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Pick up CSVs\n",
        "# =========================\n",
        "patients_p   = find_one_any(DATA_DIR, [\"patients.csv\"])\n",
        "admissions_p = find_one_any(DATA_DIR, [\"admissions.csv\"])\n",
        "vitals_p     = find_one_any(DATA_DIR, [\"vitalsign.csv\"])\n",
        "labevents_p  = find_one_any(DATA_DIR, [\"labevents.csv\"])\n",
        "d_labitems_p = find_one_any(DATA_DIR, [\"d_labitems.csv\"])\n",
        "presc_p      = find_one_any(DATA_DIR, [\"prescriptions.csv\"])\n",
        "pharmacy_p   = find_one_any(DATA_DIR, [\"pharmacy.csv\"])\n",
        "\n",
        "patients   = read_csv_auto(patients_p)\n",
        "admissions = read_csv_auto(admissions_p)\n",
        "vitals     = read_csv_auto(vitals_p)\n",
        "labevents  = read_csv_auto(labevents_p)\n",
        "d_labitems = read_csv_auto(d_labitems_p)\n",
        "presc      = read_csv_auto(presc_p)\n",
        "pharmacy   = read_csv_auto(pharmacy_p)\n",
        "\n",
        "print_header(\"Files present\")\n",
        "print({\n",
        "    \"patients\": patients is not None,\n",
        "    \"admissions\": admissions is not None,\n",
        "    \"vitals\": vitals is not None,\n",
        "    \"labevents\": labevents is not None,\n",
        "    \"d_labitems\": d_labitems is not None,\n",
        "    \"prescriptions\": presc is not None,\n",
        "    \"pharmacy\": pharmacy is not None,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5fc5dd14",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Data preparation\n",
        "# =========================\n",
        "t0 = time.time()\n",
        "adm = admissions.copy()\n",
        "for c in (\"admittime\", \"dischtime\"):\n",
        "    if c in adm.columns:\n",
        "        adm[c] = pd.to_datetime(adm[c], errors=\"coerce\")\n",
        "adm[\"los_days\"] = (adm[\"dischtime\"] - adm[\"admittime\"]).dt.total_seconds()/86400.0\n",
        "\n",
        "pat = patients.copy()\n",
        "if \"sex\" not in pat.columns and \"gender\" in pat.columns:\n",
        "    pat = pat.rename(columns={\"gender\": \"sex\"})\n",
        "for c in (\"anchor_year\", \"anchor_age\"):\n",
        "    if c in pat.columns:\n",
        "        pat[c] = pd.to_numeric(pat[c], errors=\"coerce\")\n",
        "\n",
        "# Map patient attrs to admissions rows\n",
        "anchor_year_s = pat.set_index(\"subject_id\")[\"anchor_year\"] if \"anchor_year\" in pat.columns else None\n",
        "anchor_age_s  = pat.set_index(\"subject_id\")[\"anchor_age\"]  if \"anchor_age\"  in pat.columns else None\n",
        "dob_s         = pat.set_index(\"subject_id\")[\"dob\"]          if \"dob\"         in pat.columns else None\n",
        "\n",
        "ay = adm[\"subject_id\"].map(anchor_year_s) if anchor_year_s is not None else None\n",
        "aa = adm[\"subject_id\"].map(anchor_age_s)  if anchor_age_s  is not None else None\n",
        "db = adm[\"subject_id\"].map(dob_s)         if dob_s         is not None else None\n",
        "\n",
        "def compute_age_at_admit_safe(admittime, anchor_year=None, anchor_age=None, dob=None):\n",
        "    y = pd.to_datetime(admittime, errors=\"coerce\").dt.year\n",
        "    age = pd.Series(np.nan, index=y.index, dtype=float)\n",
        "    if anchor_year is not None and anchor_age is not None:\n",
        "        ay = pd.to_numeric(anchor_year, errors=\"coerce\")\n",
        "        aa = pd.to_numeric(anchor_age,  errors=\"coerce\")\n",
        "        age = (aa + (y - ay)).astype(float)\n",
        "    if dob is not None:\n",
        "        dob_dt = pd.to_datetime(dob, errors=\"coerce\")\n",
        "        age_from_dob = (pd.to_datetime(admittime, errors=\"coerce\") - dob_dt).dt.total_seconds() / (365.25*24*3600)\n",
        "        age = age.where(age.notna(), age_from_dob)\n",
        "    return age.clip(lower=0, upper=120)\n",
        "\n",
        "adm[\"age_at_admit\"] = compute_age_at_admit_safe(adm[\"admittime\"], ay, aa, db)\n",
        "\n",
        "# per-patient rollup\n",
        "adm_subj = adm.groupby(\"subject_id\").agg(\n",
        "    admits=(\"hadm_id\",\"nunique\"),\n",
        "    age_at_first_admit=(\"age_at_admit\",\"min\"),\n",
        "    mean_los_days=(\"los_days\",\"mean\")\n",
        ").reset_index()\n",
        "\n",
        "if \"sex\" in pat.columns:\n",
        "    adm_subj = adm_subj.merge(pat[[\"subject_id\",\"sex\"]], on=\"subject_id\", how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ae1d139d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Vitals (per patient) — ensure numeric before mean()\n",
        "# =========================\n",
        "vitals_subj = None\n",
        "if vitals is not None and \"subject_id\" in vitals.columns:\n",
        "    v = vitals.copy()\n",
        "    rename_map = {\n",
        "        \"heartrate\":\"heartrate\", \"heart_rate\":\"heartrate\", \"hr\":\"heartrate\",\n",
        "        \"resp_rate\":\"resprate\", \"respiratory_rate\":\"resprate\", \"rr\":\"resprate\",\n",
        "        \"o2sat\":\"o2sat\", \"spo2\":\"o2sat\", \"oxygen_saturation\":\"o2sat\",\n",
        "        \"sbp\":\"sbp\", \"systolic\":\"sbp\", \"systolic_bp\":\"sbp\",\n",
        "        \"dbp\":\"dbp\", \"diastolic\":\"dbp\", \"diastolic_bp\":\"dbp\",\n",
        "        \"temperature\":\"temperature\", \"temp\":\"temperature\",\n",
        "        \"weight\":\"weight_kg\", \"weight_kg\":\"weight_kg\",\n",
        "        \"height\":\"height_cm\", \"height_cm\":\"height_cm\"\n",
        "    }\n",
        "    lowcols = {c: c.lower() for c in v.columns}\n",
        "    ren = {orig: rename_map[low] for orig, low in lowcols.items() if low in rename_map}\n",
        "    v = v.rename(columns=ren)\n",
        "    keep = [c for c in [\"temperature\",\"heartrate\",\"resprate\",\"o2sat\",\"sbp\",\"dbp\",\"weight_kg\",\"height_cm\"] if c in v.columns]\n",
        "    if keep:\n",
        "        for c in keep:\n",
        "            v[c] = pd.to_numeric(v[c], errors=\"coerce\")\n",
        "        g = v.groupby(\"subject_id\")[keep].mean()  # numeric-only\n",
        "        g = g.reset_index()\n",
        "        if {\"weight_kg\",\"height_cm\"}.issubset(g.columns):\n",
        "            h_m = g[\"height_cm\"] / 100.0\n",
        "            with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "                bmi = g[\"weight_kg\"] / (h_m**2)\n",
        "            g[\"bmi\"] = bmi.replace([np.inf, -np.inf], np.nan)\n",
        "        g.columns = [\"subject_id\"] + [f\"vital_{c}_mean\" for c in g.columns[1:]]\n",
        "        vitals_subj = g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8c80ad8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Labs (per patient) — numeric guard\n",
        "# =========================\n",
        "lab_subj = None\n",
        "if (labevents is not None) and (d_labitems is not None):\n",
        "    dli = d_labitems.copy()\n",
        "    dli[\"label_l\"] = dli[\"label\"].astype(str).str.lower()\n",
        "    lab_keep = dli[dli[\"label_l\"].str.contains(\n",
        "        r\"glucose|hba1c|hemoglobin|creatinine|cholesterol|triglyceride|hdl|ldl\",\n",
        "        regex=True, na=False\n",
        "    )][[\"itemid\",\"label_l\"]]\n",
        "\n",
        "    le = labevents.copy().dropna(subset=[\"itemid\",\"valuenum\"])\n",
        "    le[\"valuenum\"] = pd.to_numeric(le[\"valuenum\"], errors=\"coerce\")\n",
        "    le = le[le[\"itemid\"].isin(lab_keep[\"itemid\"])]\n",
        "    le = le.merge(adm[[\"hadm_id\",\"subject_id\"]], on=\"hadm_id\", how=\"left\")\n",
        "    le = coalesce_subject_id(le).dropna(subset=[\"subject_id\"])\n",
        "    le[\"subject_id\"] = pd.to_numeric(le[\"subject_id\"], errors=\"coerce\")\n",
        "\n",
        "    le = le.merge(lab_keep, on=\"itemid\", how=\"left\")\n",
        "    lab_subj = (\n",
        "        le.groupby([\"subject_id\",\"label_l\"])[\"valuenum\"].mean()\n",
        "          .unstack(fill_value=np.nan)\n",
        "          .reset_index()\n",
        "    )\n",
        "    lab_subj.columns = [\"subject_id\"] + [f\"lab_{str(c).replace(' ','_')}_mean\" for c in lab_subj.columns[1:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b93e0ead",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Med history (per patient)\n",
        "# =========================\n",
        "med_subj = None\n",
        "if presc is not None and \"drug\" in presc.columns:\n",
        "    rx = presc.copy()\n",
        "    rx[\"drug\"] = rx[\"drug\"].astype(str).str.lower()\n",
        "    rx = rx.merge(adm[[\"hadm_id\",\"subject_id\"]], on=\"hadm_id\", how=\"left\")\n",
        "    rx = coalesce_subject_id(rx).dropna(subset=[\"subject_id\"])\n",
        "    rx[\"subject_id\"] = pd.to_numeric(rx[\"subject_id\"], errors=\"coerce\")\n",
        "\n",
        "    rx_count = rx.groupby(\"subject_id\").agg(\n",
        "        rx_count=(\"drug\",\"count\"),\n",
        "        rx_unique=(\"drug\",\"nunique\")\n",
        "    ).reset_index()\n",
        "\n",
        "    def flag_any(series: pd.Series, keywords):\n",
        "        if series.empty: return 0\n",
        "        pat = r\"(\" + r\"|\".join(re.escape(k) for k in keywords) + r\")\"\n",
        "        return int(series.str.contains(pat, na=False).any())\n",
        "\n",
        "    rows = []\n",
        "    for sid, g in rx.groupby(\"subject_id\"):\n",
        "        s = g[\"drug\"]\n",
        "        rows.append({\n",
        "            \"subject_id\": sid,\n",
        "            \"rx_insulin\":   flag_any(s, [\"insulin\"]),\n",
        "            \"rx_metformin\": flag_any(s, [\"metformin\"]),\n",
        "            \"rx_statin\":    flag_any(s, [\"atorvastatin\",\"rosuvastatin\",\"simvastatin\",\"pravastatin\",\"lovastatin\"])\n",
        "        })\n",
        "    rx_flags = pd.DataFrame(rows)\n",
        "    med_subj = rx_count.merge(rx_flags, on=\"subject_id\", how=\"outer\").fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "825c7945",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================\n",
            "Feature engineering finished in 172.5s\n",
            "======================================\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# “Notes” proxy via medication text (per patient)\n",
        "# =========================\n",
        "tok_subj = None\n",
        "if pharmacy is not None and {\"hadm_id\",\"medication\"}.issubset(pharmacy.columns):\n",
        "    ph = pharmacy[[\"hadm_id\",\"medication\"]].copy()\n",
        "    ph[\"medication\"] = ph[\"medication\"].astype(str)\n",
        "    ph = ph.merge(adm[[\"hadm_id\",\"subject_id\"]], on=\"hadm_id\", how=\"left\")\n",
        "    ph = coalesce_subject_id(ph).dropna(subset=[\"subject_id\"])\n",
        "    ph[\"subject_id\"] = pd.to_numeric(ph[\"subject_id\"], errors=\"coerce\")\n",
        "\n",
        "    text_per_subject = ph.groupby(\"subject_id\")[\"medication\"].apply(lambda s: \" \".join(s)).reset_index()\n",
        "    text_per_subject[\"medication\"] = text_per_subject[\"medication\"].fillna(\"\")\n",
        "    if len(text_per_subject) > 0:\n",
        "        tfidf = TfidfVectorizer(\n",
        "            max_features=TFIDF_MAX_FEATURES,\n",
        "            stop_words=\"english\",\n",
        "            token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z\\-]+\\b\"\n",
        "        )\n",
        "        Xtf = tfidf.fit_transform(text_per_subject[\"medication\"])\n",
        "        tok_subj = pd.DataFrame(Xtf.toarray(), columns=[f\"tok_{t}\" for t in tfidf.get_feature_names_out()])\n",
        "        tok_subj.insert(0, \"subject_id\", text_per_subject[\"subject_id\"].values)\n",
        "\n",
        "print_header(f\"Feature engineering finished in {time.time()-t0:.1f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "403c5c9e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================================\n",
            "PCA: n_components=10, explained variance=0.429\n",
            "==============================================\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Assemble feature table (per patient)\n",
        "# =========================\n",
        "frames = [adm_subj]\n",
        "for f in [vitals_subj, lab_subj, med_subj, tok_subj]:\n",
        "    if f is not None:\n",
        "        frames.append(f)\n",
        "\n",
        "feat = reduce(lambda L, R: pd.merge(L, R, on=\"subject_id\", how=\"outer\"), frames).copy()\n",
        "\n",
        "# Handle sex (if present) as one-hot\n",
        "if \"sex\" in feat.columns:\n",
        "    feat[\"sex\"] = feat[\"sex\"].fillna(\"Unknown\")\n",
        "    sex_ohe = pd.get_dummies(feat[\"sex\"], prefix=\"sex\", dummy_na=False)\n",
        "    feat = pd.concat([feat.drop(columns=[\"sex\"]), sex_ohe], axis=1)\n",
        "\n",
        "# Build numeric matrix; drop ID\n",
        "num_df = feat.select_dtypes(include=np.number).copy()\n",
        "if \"subject_id\" in num_df.columns:\n",
        "    num_df = num_df.drop(columns=[\"subject_id\"])\n",
        "\n",
        "# Fill numeric NaNs with medians and tame outliers\n",
        "num_df = num_df.apply(lambda s: s.fillna(s.median()), axis=0)\n",
        "q_low  = num_df.quantile(0.005)\n",
        "q_high = num_df.quantile(0.995)\n",
        "num_df = num_df.clip(q_low, q_high, axis=1)\n",
        "\n",
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(num_df.values)\n",
        "\n",
        "# Optional PCA\n",
        "n_comp = min(PCA_COMPONENTS_MAX, X.shape[1])\n",
        "if DO_PCA and n_comp >= 2:\n",
        "    pca = PCA(n_components=n_comp, random_state=42)\n",
        "    X_use = pca.fit_transform(X)\n",
        "    print_header(f\"PCA: n_components={n_comp}, explained variance={pca.explained_variance_ratio_.sum():.3f}\")\n",
        "else:\n",
        "    pca = None\n",
        "    X_use = X\n",
        "\n",
        "N = X_use.shape[0]\n",
        "rng = np.random.default_rng(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1916f85b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=======\n",
            "HDBSCAN\n",
            "=======\n",
            "cfg={'min_cluster_size': 40, 'min_samples': None, 'metric': 'euclidean', 'cluster_selection_epsilon': 0.0} -> Sil=0.674, CH=5572.0, noise=0.529\n",
            "cfg={'min_cluster_size': 50, 'min_samples': None, 'metric': 'euclidean', 'cluster_selection_epsilon': 0.0} -> Sil=0.755, CH=6805.9, noise=0.524\n",
            "cfg={'min_cluster_size': 50, 'min_samples': 5, 'metric': 'euclidean', 'cluster_selection_epsilon': 0.0} -> Sil=0.582, CH=3055.8, noise=0.576\n",
            "cfg={'min_cluster_size': 50, 'min_samples': None, 'metric': 'euclidean', 'cluster_selection_epsilon': 0.0} -> Sil=0.755, CH=6805.9, noise=0.524\n",
            "cfg={'min_cluster_size': 40, 'min_samples': 20, 'metric': 'euclidean', 'cluster_selection_epsilon': 0.1, 'cluster_selection_method': 'leaf'} -> Sil=0.436, CH=2940.6, noise=0.733\n",
            "cfg={'min_cluster_size': 60, 'min_samples': 30, 'metric': 'euclidean', 'cluster_selection_epsilon': 0.1, 'cluster_selection_method': 'leaf'} -> Sil=0.437, CH=5339.0, noise=0.750\n",
            "cfg={'min_cluster_size': 100, 'min_samples': None, 'metric': 'euclidean', 'cluster_selection_epsilon': 0.0} -> Sil=0.704, CH=4198.6, noise=0.481\n",
            "cfg={'min_cluster_size': 100, 'min_samples': 10, 'metric': 'euclidean', 'cluster_selection_epsilon': 0.0} -> Sil=0.703, CH=6453.0, noise=0.486\n",
            "cfg={'min_cluster_size': 50, 'min_samples': 5, 'metric': 'euclidean', 'cluster_selection_epsilon': 0.5} -> Sil=0.558, CH=2791.4, noise=0.483\n",
            "cfg={'min_cluster_size': 100, 'min_samples': 10, 'metric': 'euclidean', 'cluster_selection_epsilon': 0.5} -> Sil=0.703, CH=6453.0, noise=0.486\n",
            "\n",
            "Best config: {'min_cluster_size': 50, 'min_samples': None, 'metric': 'euclidean', 'cluster_selection_epsilon': 0.0}\n",
            "Clusters: 4\n",
            "Noise fraction: 0.520\n",
            "Silhouette: 0.752\n",
            "Calinski–Harabasz: 151533.2\n",
            "HDBSCAN total time: 283.3s\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# HDBSCAN\n",
        "# =========================\n",
        "if not HAS_HDBSCAN:\n",
        "    print_header(\"HDBSCAN not installed — skipping HDBSCAN and using K-Means only.\")\n",
        "    labels_all = np.full(N, -1, dtype=int)\n",
        "    strengths = np.zeros(N, dtype=float)\n",
        "    best_cfg = None\n",
        "    sil_full = ch_full = np.nan\n",
        "    noise_frac_full = 1.0\n",
        "else:\n",
        "    print_header(\"HDBSCAN\")\n",
        "    t1 = time.time()\n",
        "\n",
        "    # 0) Filter/repair grid for unsupported metrics\n",
        "    fixed_grid = []\n",
        "    for cfg in SEARCH_GRID:\n",
        "        cfg = cfg.copy()\n",
        "        m = cfg.get(\"metric\", \"euclidean\")\n",
        "        if not _metric_supported(m):\n",
        "            print(f\"[info] Metric '{m}' not supported; forcing 'euclidean' for cfg={cfg}.\")\n",
        "            cfg[\"metric\"] = \"euclidean\"\n",
        "        fixed_grid.append(cfg)\n",
        "\n",
        "    # 1) Build subset for search\n",
        "    if N > SEARCH_SUBSAMPLE_MAX_N:\n",
        "        idx_search = rng.choice(N, SEARCH_SUBSAMPLE_MAX_N, replace=False)\n",
        "    else:\n",
        "        idx_search = np.arange(N)\n",
        "\n",
        "    best_score = None  # (sil, ch, -noise_frac)\n",
        "    best_cfg   = None\n",
        "\n",
        "    for cfg in fixed_grid:\n",
        "        metric = cfg.get(\"metric\", \"euclidean\")\n",
        "        method = cfg.get(\"cluster_selection_method\", HDBSCAN_KW[\"cluster_selection_method\"])\n",
        "\n",
        "        # prepare space for this metric\n",
        "        X_search = X_use[idx_search]\n",
        "        if metric == \"cosine\":\n",
        "            X_space = normalize(X_search)  # L2-normalize rows\n",
        "            sil_metric = \"cosine\"\n",
        "        else:\n",
        "            X_space = X_search\n",
        "            sil_metric = \"euclidean\"\n",
        "\n",
        "        cl = hdbscan.HDBSCAN(\n",
        "            min_cluster_size=cfg[\"min_cluster_size\"],\n",
        "            min_samples=cfg[\"min_samples\"],\n",
        "            metric=metric,\n",
        "            cluster_selection_epsilon=cfg.get(\"cluster_selection_epsilon\", 0.0),\n",
        "            cluster_selection_method=method,\n",
        "            **{k:v for k,v in HDBSCAN_KW.items() if k != \"cluster_selection_method\"}\n",
        "        )\n",
        "        labels_sub = cl.fit_predict(X_space)\n",
        "        core_mask = labels_sub >= 0\n",
        "        if core_mask.sum() < 2 or len(np.unique(labels_sub[core_mask])) < 2:\n",
        "            continue\n",
        "\n",
        "        sil = silhouette_score(X_space[core_mask], labels_sub[core_mask], metric=sil_metric)\n",
        "        ch  = calinski_harabasz_score(X_space[core_mask], labels_sub[core_mask])\n",
        "        noise_frac = float((labels_sub < 0).sum()) / len(labels_sub)\n",
        "        score = (sil, ch, -noise_frac)\n",
        "\n",
        "        print(f\"cfg={cfg} -> Sil={sil:.3f}, CH={ch:.1f}, noise={noise_frac:.3f}\")\n",
        "\n",
        "        def _safe_tuple(t):  # handle NaNs\n",
        "            return tuple(x if np.isfinite(x) else -np.inf for x in t)\n",
        "        if (best_score is None) or (_safe_tuple(score) > _safe_tuple(best_score)):\n",
        "            best_score = score\n",
        "            best_cfg   = cfg\n",
        "\n",
        "    if best_cfg is None:\n",
        "        best_cfg = {\"min_cluster_size\": 50, \"min_samples\": None, \"metric\": \"euclidean\", \"cluster_selection_epsilon\": 0.0}\n",
        "        print(f\"[warn] No valid clustering found in sweep; falling back to {best_cfg}\")\n",
        "\n",
        "    # 2) Final model fit on a (slightly bigger) subset — respect metric space\n",
        "    if N > FINAL_SUBSAMPLE_MAX_N:\n",
        "        idx_final = rng.choice(N, FINAL_SUBSAMPLE_MAX_N, replace=False)\n",
        "    else:\n",
        "        idx_final = np.arange(N)\n",
        "\n",
        "    metric_final = best_cfg.get(\"metric\", \"euclidean\")\n",
        "    method_final = best_cfg.get(\"cluster_selection_method\", HDBSCAN_KW[\"cluster_selection_method\"])\n",
        "\n",
        "    X_finalfit = X_use[idx_final]\n",
        "    X_all_eval = X_use.copy()\n",
        "    if metric_final == \"cosine\":\n",
        "        X_finalfit = normalize(X_finalfit)\n",
        "        X_all_eval = normalize(X_all_eval)\n",
        "        sil_metric_final = \"cosine\"\n",
        "    else:\n",
        "        sil_metric_final = \"euclidean\"\n",
        "\n",
        "    final_cl = hdbscan.HDBSCAN(\n",
        "        min_cluster_size=best_cfg[\"min_cluster_size\"],\n",
        "        min_samples=best_cfg[\"min_samples\"],\n",
        "        metric=metric_final,\n",
        "        cluster_selection_epsilon=best_cfg.get(\"cluster_selection_epsilon\", 0.0),\n",
        "        cluster_selection_method=method_final,\n",
        "        **{k:v for k,v in HDBSCAN_KW.items() if k != \"cluster_selection_method\"}\n",
        "    )\n",
        "    final_cl.fit(X_finalfit)\n",
        "\n",
        "    # 3) Label ALL points via approximate_predict (in same metric space)\n",
        "    labels_all, strengths = hdbscan.approximate_predict(final_cl, X_all_eval)\n",
        "\n",
        "    # Metrics on core-only (exclude noise) in same space\n",
        "    mask_core = labels_all >= 0\n",
        "    n_clusters_core = len(np.unique(labels_all[mask_core])) if mask_core.sum() > 1 else 0\n",
        "    if mask_core.sum() > 1 and n_clusters_core >= 2:\n",
        "        sil_full = silhouette_score(X_all_eval[mask_core], labels_all[mask_core], metric=sil_metric_final)\n",
        "        ch_full  = calinski_harabasz_score(X_all_eval[mask_core], labels_all[mask_core])\n",
        "    else:\n",
        "        sil_full, ch_full = np.nan, np.nan\n",
        "\n",
        "    noise_frac_full = float((labels_all < 0).sum()) / len(labels_all)\n",
        "\n",
        "    print(f\"\\nBest config: {best_cfg}\")\n",
        "    print(f\"Clusters: {n_clusters_core}\")\n",
        "    print(f\"Noise fraction: {noise_frac_full:.3f}\")\n",
        "    print(f\"Silhouette: {np.nan if not np.isfinite(sil_full) else round(sil_full, 3)}\")\n",
        "    print(f\"Calinski–Harabasz: {np.nan if not np.isfinite(ch_full) else round(ch_full, 1)}\")\n",
        "    print(f\"HDBSCAN total time: {time.time()-t1:.1f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "27fd252c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================================\n",
            "HDBSCAN cluster profiles (medians/percentages)\n",
            "==============================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n</th>\n",
              "      <th>borderline_pct</th>\n",
              "      <th>mean_strength</th>\n",
              "      <th>age_med</th>\n",
              "      <th>admits_med</th>\n",
              "      <th>los_med</th>\n",
              "      <th>lab_%_hemoglobin_a1c_mean_med</th>\n",
              "      <th>lab_24_hr_creatinine_mean_med</th>\n",
              "      <th>lab_albumin/creatinine,_urine_mean_med</th>\n",
              "      <th>lab_amylase/creatinine_ratio,_urine_mean_med</th>\n",
              "      <th>lab_carboxyhemoglobin_mean_med</th>\n",
              "      <th>lab_cholesterol_ratio_(total/hdl)_mean_med</th>\n",
              "      <th>lab_cholesterol,_ascites_mean_med</th>\n",
              "      <th>lab_cholesterol,_body_fluid_mean_med</th>\n",
              "      <th>lab_cholesterol,_hdl_mean_med</th>\n",
              "      <th>lab_cholesterol,_ldl,_calculated_mean_med</th>\n",
              "      <th>lab_cholesterol,_ldl,_measured_mean_med</th>\n",
              "      <th>lab_cholesterol,_pleural_mean_med</th>\n",
              "      <th>lab_cholesterol,_total_mean_med</th>\n",
              "      <th>lab_creatinine_mean_med</th>\n",
              "      <th>lab_creatinine_clearance_mean_med</th>\n",
              "      <th>lab_creatinine,_ascites_mean_med</th>\n",
              "      <th>lab_creatinine,_body_fluid_mean_med</th>\n",
              "      <th>lab_creatinine,_joint_fluid_mean_med</th>\n",
              "      <th>lab_creatinine,_pleural_mean_med</th>\n",
              "      <th>lab_creatinine,_serum_mean_med</th>\n",
              "      <th>lab_creatinine,_urine_mean_med</th>\n",
              "      <th>lab_creatinine,_whole_blood_mean_med</th>\n",
              "      <th>lab_fetal_hemoglobin_mean_med</th>\n",
              "      <th>lab_glucose_mean_med</th>\n",
              "      <th>lab_glucose,_ascites_mean_med</th>\n",
              "      <th>lab_glucose,_body_fluid_mean_med</th>\n",
              "      <th>lab_glucose,_csf_mean_med</th>\n",
              "      <th>lab_glucose,_joint_fluid_mean_med</th>\n",
              "      <th>lab_glucose,_pleural_mean_med</th>\n",
              "      <th>lab_glucose,_urine_mean_med</th>\n",
              "      <th>lab_hemoglobin_mean_med</th>\n",
              "      <th>lab_hemoglobin_a2_mean_med</th>\n",
              "      <th>lab_hemoglobin_c_mean_med</th>\n",
              "      <th>lab_hemoglobin_f_mean_med</th>\n",
              "      <th>lab_hemoglobin_other_mean_med</th>\n",
              "      <th>lab_hemoglobin,_calculated_mean_med</th>\n",
              "      <th>lab_methemoglobin_mean_med</th>\n",
              "      <th>lab_p50_of_hemoglobin_mean_med</th>\n",
              "      <th>lab_protein/creatinine_ratio_mean_med</th>\n",
              "      <th>lab_triglycerides_mean_med</th>\n",
              "      <th>lab_triglycerides,_ascites_mean_med</th>\n",
              "      <th>lab_triglycerides,_pleural_mean_med</th>\n",
              "      <th>lab_urine_creatinine_mean_med</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hdb_cluster</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11158</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.777461</td>\n",
              "      <td>65.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.660417</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>1106.5</td>\n",
              "      <td>20.966667</td>\n",
              "      <td>6.7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.25</td>\n",
              "      <td>45.5</td>\n",
              "      <td>88.0</td>\n",
              "      <td>51.833333</td>\n",
              "      <td>93.0</td>\n",
              "      <td>102.00</td>\n",
              "      <td>47.75</td>\n",
              "      <td>168.583333</td>\n",
              "      <td>0.819512</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.30</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116.3125</td>\n",
              "      <td>121.333333</td>\n",
              "      <td>82.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>10.950000</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.90</td>\n",
              "      <td>13.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3</td>\n",
              "      <td>112.50</td>\n",
              "      <td>71.5</td>\n",
              "      <td>30.25</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.758998</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.660764</td>\n",
              "      <td>5.333333</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>102.0</td>\n",
              "      <td>110.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>181.000000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>113.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.75</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.5</td>\n",
              "      <td>60.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.180000</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.95</td>\n",
              "      <td>14.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2</td>\n",
              "      <td>88.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3374</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.967372</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.116319</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>1422.0</td>\n",
              "      <td>9.100000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>103.0</td>\n",
              "      <td>110.00</td>\n",
              "      <td>90.00</td>\n",
              "      <td>183.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>159.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.60</td>\n",
              "      <td>90.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>102.5000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>61.0</td>\n",
              "      <td>17.5</td>\n",
              "      <td>104.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.766667</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>100.55</td>\n",
              "      <td>33.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>73.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>141872</td>\n",
              "      <td>8.005808</td>\n",
              "      <td>0.679673</td>\n",
              "      <td>41.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.543056</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>1205.0</td>\n",
              "      <td>9.900000</td>\n",
              "      <td>3.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>106.0</td>\n",
              "      <td>117.50</td>\n",
              "      <td>70.00</td>\n",
              "      <td>189.041667</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>96.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.00</td>\n",
              "      <td>106.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>57.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.600000</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.85</td>\n",
              "      <td>14.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>105.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.00</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  n  borderline_pct  mean_strength  age_med  admits_med  \\\n",
              "hdb_cluster                                                               \n",
              "0             11158        0.000000       0.777461     65.0         1.0   \n",
              "1              4965        0.000000       0.758998     32.0         1.0   \n",
              "2              3374        0.000000       0.967372     42.0         1.0   \n",
              "3            141872        8.005808       0.679673     41.0         1.0   \n",
              "\n",
              "              los_med  lab_%_hemoglobin_a1c_mean_med  \\\n",
              "hdb_cluster                                            \n",
              "0            5.660417                       5.600000   \n",
              "1            2.660764                       5.333333   \n",
              "2            2.116319                       5.500000   \n",
              "3            0.543056                       5.600000   \n",
              "\n",
              "             lab_24_hr_creatinine_mean_med  \\\n",
              "hdb_cluster                                  \n",
              "0                                   1106.5   \n",
              "1                                   1300.0   \n",
              "2                                   1422.0   \n",
              "3                                   1205.0   \n",
              "\n",
              "             lab_albumin/creatinine,_urine_mean_med  \\\n",
              "hdb_cluster                                           \n",
              "0                                         20.966667   \n",
              "1                                          6.900000   \n",
              "2                                          9.100000   \n",
              "3                                          9.900000   \n",
              "\n",
              "             lab_amylase/creatinine_ratio,_urine_mean_med  \\\n",
              "hdb_cluster                                                 \n",
              "0                                                     6.7   \n",
              "1                                                     NaN   \n",
              "2                                                     NaN   \n",
              "3                                                     3.4   \n",
              "\n",
              "             lab_carboxyhemoglobin_mean_med  \\\n",
              "hdb_cluster                                   \n",
              "0                                       2.0   \n",
              "1                                       1.5   \n",
              "2                                       2.0   \n",
              "3                                       2.0   \n",
              "\n",
              "             lab_cholesterol_ratio_(total/hdl)_mean_med  \\\n",
              "hdb_cluster                                               \n",
              "0                                                  3.25   \n",
              "1                                                  3.10   \n",
              "2                                                  3.20   \n",
              "3                                                  3.30   \n",
              "\n",
              "             lab_cholesterol,_ascites_mean_med  \\\n",
              "hdb_cluster                                      \n",
              "0                                         45.5   \n",
              "1                                          NaN   \n",
              "2                                          NaN   \n",
              "3                                          NaN   \n",
              "\n",
              "             lab_cholesterol,_body_fluid_mean_med  \\\n",
              "hdb_cluster                                         \n",
              "0                                            88.0   \n",
              "1                                             NaN   \n",
              "2                                             NaN   \n",
              "3                                             NaN   \n",
              "\n",
              "             lab_cholesterol,_hdl_mean_med  \\\n",
              "hdb_cluster                                  \n",
              "0                                51.833333   \n",
              "1                                59.000000   \n",
              "2                                58.000000   \n",
              "3                                56.000000   \n",
              "\n",
              "             lab_cholesterol,_ldl,_calculated_mean_med  \\\n",
              "hdb_cluster                                              \n",
              "0                                                 93.0   \n",
              "1                                                102.0   \n",
              "2                                                103.0   \n",
              "3                                                106.0   \n",
              "\n",
              "             lab_cholesterol,_ldl,_measured_mean_med  \\\n",
              "hdb_cluster                                            \n",
              "0                                             102.00   \n",
              "1                                             110.75   \n",
              "2                                             110.00   \n",
              "3                                             117.50   \n",
              "\n",
              "             lab_cholesterol,_pleural_mean_med  \\\n",
              "hdb_cluster                                      \n",
              "0                                        47.75   \n",
              "1                                          NaN   \n",
              "2                                        90.00   \n",
              "3                                        70.00   \n",
              "\n",
              "             lab_cholesterol,_total_mean_med  lab_creatinine_mean_med  \\\n",
              "hdb_cluster                                                             \n",
              "0                                 168.583333                 0.819512   \n",
              "1                                 181.000000                 0.650000   \n",
              "2                                 183.000000                 0.800000   \n",
              "3                                 189.041667                 0.825000   \n",
              "\n",
              "             lab_creatinine_clearance_mean_med  \\\n",
              "hdb_cluster                                      \n",
              "0                                         59.0   \n",
              "1                                        113.0   \n",
              "2                                        159.0   \n",
              "3                                         96.0   \n",
              "\n",
              "             lab_creatinine,_ascites_mean_med  \\\n",
              "hdb_cluster                                     \n",
              "0                                         0.8   \n",
              "1                                         NaN   \n",
              "2                                         1.0   \n",
              "3                                         0.7   \n",
              "\n",
              "             lab_creatinine,_body_fluid_mean_med  \\\n",
              "hdb_cluster                                        \n",
              "0                                            1.3   \n",
              "1                                            1.6   \n",
              "2                                            5.9   \n",
              "3                                            NaN   \n",
              "\n",
              "             lab_creatinine,_joint_fluid_mean_med  \\\n",
              "hdb_cluster                                         \n",
              "0                                             NaN   \n",
              "1                                             NaN   \n",
              "2                                             NaN   \n",
              "3                                             NaN   \n",
              "\n",
              "             lab_creatinine,_pleural_mean_med  lab_creatinine,_serum_mean_med  \\\n",
              "hdb_cluster                                                                     \n",
              "0                                         0.7                            1.30   \n",
              "1                                         NaN                            0.75   \n",
              "2                                         0.7                            0.60   \n",
              "3                                         0.7                            1.00   \n",
              "\n",
              "             lab_creatinine,_urine_mean_med  \\\n",
              "hdb_cluster                                   \n",
              "0                                      76.0   \n",
              "1                                      79.0   \n",
              "2                                      90.0   \n",
              "3                                     106.0   \n",
              "\n",
              "             lab_creatinine,_whole_blood_mean_med  \\\n",
              "hdb_cluster                                         \n",
              "0                                             0.9   \n",
              "1                                             0.7   \n",
              "2                                             0.9   \n",
              "3                                             0.9   \n",
              "\n",
              "             lab_fetal_hemoglobin_mean_med  lab_glucose_mean_med  \\\n",
              "hdb_cluster                                                        \n",
              "0                                      0.0              116.3125   \n",
              "1                                      0.0               95.0000   \n",
              "2                                      NaN              102.5000   \n",
              "3                                      0.0               98.0000   \n",
              "\n",
              "             lab_glucose,_ascites_mean_med  lab_glucose,_body_fluid_mean_med  \\\n",
              "hdb_cluster                                                                    \n",
              "0                               121.333333                              82.0   \n",
              "1                                      NaN                              34.5   \n",
              "2                                59.000000                               NaN   \n",
              "3                               120.000000                              57.0   \n",
              "\n",
              "             lab_glucose,_csf_mean_med  lab_glucose,_joint_fluid_mean_med  \\\n",
              "hdb_cluster                                                                 \n",
              "0                                 70.0                              113.0   \n",
              "1                                 60.0                                NaN   \n",
              "2                                 61.0                               17.5   \n",
              "3                                 63.0                               80.0   \n",
              "\n",
              "             lab_glucose,_pleural_mean_med  lab_glucose,_urine_mean_med  \\\n",
              "hdb_cluster                                                               \n",
              "0                                    110.0                         17.0   \n",
              "1                                      NaN                          NaN   \n",
              "2                                    104.0                          NaN   \n",
              "3                                     94.0                          5.0   \n",
              "\n",
              "             lab_hemoglobin_mean_med  lab_hemoglobin_a2_mean_med  \\\n",
              "hdb_cluster                                                        \n",
              "0                          10.950000                         2.5   \n",
              "1                          12.180000                         2.5   \n",
              "2                          12.766667                         2.4   \n",
              "3                          13.600000                         2.5   \n",
              "\n",
              "             lab_hemoglobin_c_mean_med  lab_hemoglobin_f_mean_med  \\\n",
              "hdb_cluster                                                         \n",
              "0                                  0.0                        0.0   \n",
              "1                                  0.0                        0.0   \n",
              "2                                  0.0                        0.0   \n",
              "3                                  0.0                        0.0   \n",
              "\n",
              "             lab_hemoglobin_other_mean_med  \\\n",
              "hdb_cluster                                  \n",
              "0                                     0.90   \n",
              "1                                     0.95   \n",
              "2                                      NaN   \n",
              "3                                    57.85   \n",
              "\n",
              "             lab_hemoglobin,_calculated_mean_med  lab_methemoglobin_mean_med  \\\n",
              "hdb_cluster                                                                    \n",
              "0                                          13.75                         0.0   \n",
              "1                                          14.10                         0.0   \n",
              "2                                          14.25                         0.0   \n",
              "3                                          14.30                         0.0   \n",
              "\n",
              "             lab_p50_of_hemoglobin_mean_med  \\\n",
              "hdb_cluster                                   \n",
              "0                                       NaN   \n",
              "1                                       NaN   \n",
              "2                                       NaN   \n",
              "3                                       NaN   \n",
              "\n",
              "             lab_protein/creatinine_ratio_mean_med  \\\n",
              "hdb_cluster                                          \n",
              "0                                              0.3   \n",
              "1                                              0.2   \n",
              "2                                              0.1   \n",
              "3                                              0.1   \n",
              "\n",
              "             lab_triglycerides_mean_med  lab_triglycerides,_ascites_mean_med  \\\n",
              "hdb_cluster                                                                    \n",
              "0                                112.50                                 71.5   \n",
              "1                                 88.00                                  NaN   \n",
              "2                                100.55                                 33.0   \n",
              "3                                105.50                                  NaN   \n",
              "\n",
              "             lab_triglycerides,_pleural_mean_med  \\\n",
              "hdb_cluster                                        \n",
              "0                                          30.25   \n",
              "1                                            NaN   \n",
              "2                                            NaN   \n",
              "3                                          30.00   \n",
              "\n",
              "             lab_urine_creatinine_mean_med  \n",
              "hdb_cluster                                 \n",
              "0                                     52.0  \n",
              "1                                     69.0  \n",
              "2                                     73.5  \n",
              "3                                     80.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =========================\n",
        "# Results & Profiles\n",
        "# =========================\n",
        "# Attach labels to subjects\n",
        "assign = feat[[\"subject_id\"]].copy()\n",
        "assign[\"hdb_cluster\"]  = labels_all                  # hdbscan labels (noise = -1)\n",
        "assign[\"hdb_strength\"] = strengths\n",
        "assign[\"hdb_borderline\"] = ((assign[\"hdb_cluster\"] >= 0) & (assign[\"hdb_strength\"] < BORDERLINE_THRESH)).astype(int)\n",
        "\n",
        "# Profile table\n",
        "profile_df = feat.merge(assign[[\"subject_id\",\"hdb_cluster\",\"hdb_strength\",\"hdb_borderline\"]],\n",
        "                        on=\"subject_id\", how=\"left\")\n",
        "\n",
        "def pick_cols(df):\n",
        "    want_prefixes = [\n",
        "        \"age_at_first_admit\", \"admits\", \"mean_los_days\",\n",
        "        \"vital_sbp_mean\", \"vital_dbp_mean\", \"vital_heartrate_mean\", \"vital_o2sat_mean\",\n",
        "        \"vital_bmi_mean\",\n",
        "        \"lab_glucose\", \"lab_hba1c\", \"lab_cholesterol\", \"lab_hdl\", \"lab_ldl\", \"lab_triglyceride\",\n",
        "        \"lab_creatinine\", \"lab_hemoglobin\",\n",
        "        \"rx_count\", \"rx_unique\", \"rx_insulin\", \"rx_metformin\", \"rx_statin\",\n",
        "        \"sex_\"\n",
        "    ]\n",
        "    cols = []\n",
        "    for pref in want_prefixes:\n",
        "        found = [c for c in df.columns if c.startswith(pref)]\n",
        "        if pref == \"sex_\":\n",
        "            cols += found\n",
        "        elif found:\n",
        "            cols.append(found[0])\n",
        "    cols = [\"hdb_cluster\", \"hdb_strength\", \"hdb_borderline\"] + list(dict.fromkeys(cols))\n",
        "    return cols\n",
        "\n",
        "cols = [c for c in pick_cols(profile_df) if c in profile_df.columns]\n",
        "\n",
        "# ---- HDBSCAN profiles (exclude noise, ensure numeric for medians) ----\n",
        "hdb_base = profile_df[profile_df[\"hdb_cluster\"] >= 0].copy()\n",
        "\n",
        "# Coerce key numeric columns used in agg (if present)\n",
        "for col in [\"age_at_first_admit\", \"admits\", \"mean_los_days\"]:\n",
        "    if col in hdb_base.columns:\n",
        "        hdb_base[col] = pd.to_numeric(hdb_base[col], errors=\"coerce\")\n",
        "\n",
        "hdb_prof = (hdb_base\n",
        "            .groupby(\"hdb_cluster\")\n",
        "            .agg(\n",
        "                n=(\"subject_id\",\"count\"),\n",
        "                borderline_pct=(\"hdb_borderline\", lambda s: 100.0*pd.to_numeric(s, errors=\"coerce\").mean()),\n",
        "                mean_strength=(\"hdb_strength\", lambda s: pd.to_numeric(s, errors=\"coerce\").mean()),\n",
        "                age_med=(\"age_at_first_admit\",\"median\") if \"age_at_first_admit\" in hdb_base.columns else (\"subject_id\",\"size\"),\n",
        "                admits_med=(\"admits\",\"median\") if \"admits\" in hdb_base.columns else (\"subject_id\",\"size\"),\n",
        "                los_med=(\"mean_los_days\",\"median\") if \"mean_los_days\" in hdb_base.columns else (\"subject_id\",\"size\"),\n",
        "            ))\n",
        "\n",
        "# Add lab medians safely\n",
        "for lab_col in [c for c in hdb_base.columns if c.startswith(\"lab_\")]:\n",
        "    hdb_base[lab_col] = pd.to_numeric(hdb_base[lab_col], errors=\"coerce\")\n",
        "    hdb_prof[f\"{lab_col}_med\"] = hdb_base.groupby(\"hdb_cluster\")[lab_col].median()\n",
        "\n",
        "print_header(\"HDBSCAN cluster profiles (medians/percentages)\")\n",
        "try:\n",
        "    from IPython.display import display\n",
        "    display(hdb_prof)\n",
        "except Exception:\n",
        "    print(hdb_prof.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c2a3aa7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=====\n",
            "Saved\n",
            "=====\n",
            "{'patient_features.csv': 'cluster_outputs\\\\patient_features.csv', 'cluster_assignments.csv': 'cluster_outputs\\\\cluster_assignments.csv', 'hdbscan_profiles.csv': 'cluster_outputs\\\\hdbscan_profiles.csv'}\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Save outputs\n",
        "# =========================\n",
        "OUT_DIR = \"Models/Cluster_Outputs\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "feat.to_csv(os.path.join(OUT_DIR, \"patient_features.csv\"), index=False)\n",
        "assign.to_csv(os.path.join(OUT_DIR, \"cluster_assignments.csv\"), index=False)\n",
        "hdb_prof.to_csv(os.path.join(OUT_DIR, \"clustered_data.csv\"))\n",
        "\n",
        "print_header(\"Saved\")\n",
        "print({\n",
        "    \"patient_features.csv\": os.path.join(OUT_DIR, \"patient_features.csv\"),\n",
        "    \"cluster_assignments.csv\": os.path.join(OUT_DIR, \"cluster_assignments.csv\"),\n",
        "    \"clustered_data.csv\": os.path.join(OUT_DIR, \"clustered_data.csv\")\n",
        "})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
